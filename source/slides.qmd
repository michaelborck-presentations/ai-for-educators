---
title: "AI for Educators"
subtitle: "Understanding Instructions at the Heart of AI"
author: "Dr. Michael Borck"
date: "2026"
format: pptx
---

![](images/440000.png)

::: {.notes}
Pause for 2-3 seconds before speaking.

"$440,000. That's what the Australian government paid Deloitte for a welfare review report earlier this year."

## The Deloitte Case

**What happened:**

- Deloitte used AI (GPT-4) to draft government reports
- Reports contained **fabricated citations** - fake studies, made-up quotes
- Australia: $440,000 welfare review - partial refund issued
- Canada: $1.6 million healthcare report - 4 incorrect citations found

**The lesson:** AI is confident even when wrong. Verification is essential.

**Why this matters for us:** Your students will encounter this. Some already are. Today, I'm going to show you how to think about AI - and how to teach others to use it wisely.
:::

## Today's Session

1. **The Real Barrier** - Why we hesitate (and why that's normal)
2. **The Core Concept** - Instructions are at the heart of ALL AI
3. **Three Techniques** - Practical tools you can use and teach
4. **Assessment Reality** - If AI can do your assignment...
5. **Ethics & Next Steps** - One commitment to try

**Companion Website:** [Link provided]

## Part 1: The Real Barrier

![](images/ai-mindset)

::: {.notes}
Before we talk about how to use AI, let's talk about something that doesn't get discussed enough.

**The elephant in the room.**
:::

## AI Shame - The Hidden Barrier

**The statistics:**

- 70% of knowledge workers use AI weekly
- 63% fear being seen as incompetent or lazy
- Most hide their AI use from colleagues

**Sound familiar?**

::: {.notes}
This creates "underground use" - people using AI without sharing best practices, without developing skills openly, without learning from each other.

**The reframe:** Using AI thoughtfully is a professional skill. Hiding it prevents growth.
:::

## Your Expertise Matters MORE, Not Less

**The fear:** "Will AI make me redundant?"

**The reality:**

- AI handles routine tasks
- YOU provide judgment, connection, inspiration
- Students don't need you less - they need you MORE
- Your domain expertise is essential for evaluating AI output

::: {.notes}
Think about calculators. Did they make maths teachers redundant? No - they changed WHAT we teach and HOW.

Same with AI. Your expertise in pedagogy, in your discipline, in understanding your students - that becomes MORE valuable, not less.
:::

## Part 2: The Core Concept

![](images/smart-intern.png)

::: {.notes}
Here's the key insight I want you to take away:

**At the heart of ALL AI are instructions.**

We sometimes call this "prompt engineering" or "context engineering" - but really, it's just giving clear instructions.

The better your instructions, the better the output.
:::

## AI is a Smart Intern Who Hallucinates

**Key insight:** AI is a **reasoning engine**, not a search engine

- Google finds information that exists
- AI generates responses based on patterns
- It doesn't "know" things - it predicts likely responses

**The Intern Analogy:**

> Think of AI like a brilliant intern. They're eager, fast, and can do amazing work. But they might confidently present completely made-up statistics.

## The Golden Rule

![](images/robot-think.png)

::: {.notes}
**AI should challenge your thinking, not replace it.**

The moment you stop questioning AI's output is the moment you become Deloitte.

**Your role:** Editor-in-Chief, not stenographer.
:::


## Part 3: Three Techniques

![](images/board-of-directors.png)

::: {.notes}
Now let's look at three practical techniques. These work for YOUR work AND you can teach them to students.

**The concept:** Get multiple expert viewpoints in one prompt

- CFO perspective (financial)
- Marketing Director (customers)
- Operations Manager (practical)
- Legal Counsel (compliance)

**Why it works:** Catches blind spots you'd miss thinking alone
:::


## Demo: Board of Directors Prompt

```
I'm redesigning my assessment for a second-year
management unit.

Act as my advisory board and analyse this from
multiple perspectives:

1. As Learning Designer: Alignment with outcomes?
2. As Academic Integrity Officer: AI vulnerability?
3. As Student Advocate: Workload and clarity?
4. As Industry Partner: Real-world relevance?

For each perspective, give me 3-4 key considerations.
```

::: {.notes}
Switch to browser and run this demo in Gemini or Claude.

## Your Turn: Try It

Think about something you're working on:

- Redesigning an assessment
- Planning a new unit or module
- Developing a policy or guideline
- Preparing for a difficult conversation

**Try the Board of Directors prompt with your situation.**

:::


## Devil's Advocate - Overcoming Confirmation Bias

![](images/devils-advocate.png)

::: {.notes}

**The problem:** We look for evidence that supports our ideas

**The solution:** Force AI to argue against your position

**Key phrases that work:**

- "Be harsh but fair"
- "Don't hold back"
- "I need to hear the hard truths"
:::

## Demo: Devil's Advocate Prompt

```
I believe that banning AI from assessments is
the best approach for maintaining academic integrity.

Play devil's advocate. Give me the strongest
possible arguments against this position.
Be harsh but fair. I want to know:

1. Why might this approach fail?
2. What am I probably not thinking about?
3. Who would this NOT work for?
4. What unintended consequences could occur?

Don't hold back - I need to hear the hard truths.
```

::: {.notes}
Switch to browser and run this demo. Point out how giving AI permission to be critical produces better feedback.

You can use this for ANY position you hold - it's about stress-testing your thinking.
:::

## Reverse Prompting - When You Don't Know What to Ask

![](images/reverse-prompting.png)


::: {.notes}

**The problem:** Sometimes the hardest part is knowing what questions to ask

**The solution:** Let AI interview YOU first

**Why it works:**

- AI understands your specific context
- Recommendations become tailored, not generic
- You discover what you don't know
:::

## Demo: Reverse Prompting

```
I want to create a policy for AI use in my
business management units.

Before giving me any advice, interview me first.
Ask me questions one at a time to understand:
- My teaching context and student level
- My current assessment types
- My concerns about AI use
- My goals for student learning
- Any constraints I'm working with

After you understand my situation, then give
me tailored recommendations.

Start with your first question.
```

::: {.notes}
Run this demo. Answer 2-3 questions from the AI to show how the conversation builds context.

This is particularly powerful when you're unsure where to start.
:::

## Part 4: Assessment Reality

![](images/billboard-rule.png)

::: {.notes}
Let's talk about the elephant in the room for educators: assessments.

Here's a simple test: **Run your assessment through AI.**

If AI can complete it independently and get a pass, the assessment reveals what was already breakable.

**This isn't about banning AI. It's about designing better assessments.**
:::

## If AI Can Do Your Assignment...

**Three options:**

**Option A: Process Documentation**
- Submit AI conversation transcript
- Annotate where AI was wrong/limited
- Reflection on how expertise improved output

**Option B: In-Class Components**
- AI-generated draft submitted before class
- In-class critique and improvement
- Live presentation of key insights

**Option C: Personal Application**
- Connect to specific local context
- Include primary data they collected
- Require unique perspective AI can't have

## Part 5: Ethics & Next Steps

![](images/hallucination-trap.png)

::: {.notes}

Remember Deloitte? Here's why it happened:

1. **AI doesn't know it's lying** - It generates plausible text
2. **Confidence â‰  Accuracy** - AI sounds equally confident right or wrong
3. **Pattern matching, not truth** - AI predicts likely responses

:::


## The Three Verification Questions

![](images/check.png)

::: {.notes}
Before trusting any AI output, ask:

1. **Can I find this source independently?**
2. **Does this statistic appear elsewhere?**
3. **Does this make logical sense?**

If you can't verify it, don't use it.

Teach your students these same questions.
:::

## The Billboard Rule

**Before sharing anything with AI, ask:**

> "Would I be comfortable if this appeared on a billboard?"

**Never share:**

- Student data or personal information
- Confidential institutional data
- Anything you wouldn't want made public

::: {.notes}
This applies to us AND to our students. Model the behaviour you want to see.
:::

![](images/key-takeaways.png)

## Key Takeaways

1. **AI shame is real** - normalize thoughtful use
2. **Instructions are everything** - clarity drives quality
3. Use **multi-perspective prompting** (Board of Directors)
4. **Challenge your ideas** (Devil's Advocate)
5. Let AI **interview you** for better context (Reverse Prompting)
6. **Always verify** - never trust blindly

## Your One Commitment

Before you leave, think about:

**One small experiment you'll try this week.**

- Use AI to draft feedback on student work (then edit it)
- Try the Board of Directors prompt on something you're planning
- Run your assessment through AI to see what happens

::: {.notes}
Start small. Scale what works. Share with colleagues.

The goal isn't to become an AI expert overnight. It's to develop judgment about when and how to use these tools.
:::

## Questions

![](images/questions.png)
![](images/website.png)

::: {.notes}

**Resources available on the companion website:**

- All prompts from today's session
- Deeper reading on AI concepts
- Interactive diagnostic for personalised learning paths
- Ethics and integrity guidelines
- Style Mirror tool (help AI write in your voice)

Thank you for your attention. I'm happy to take any questions.
:::
